---
title: Introduction to Redpanda Console
---

<head>
    <meta name="title" content="Introduction to Redpanda Console | Redpanda Docs"/>
    <meta name="description" content="Introduction to Redpanda Console documentation index page."/>
</head>

This topic contains information about deploying, configuring, and using Redpanda Console.
Some features are only available if you provide an Enterprise license key. The documentation flags 
configurable features that require a license.


## Kafka Connect

Redpanda Console provides a user interface that enables you to manage multiple Kafka connect clusters.
You can inspect or patch connectors, restart/pause/resume their tasks, and also delete a connector.
If you have configured more than one cluster, Redpanda Console will query all configured connect
clusters for their status, so that you can have an overview across all your connect clusters.

### Configuration

For each cluster you have to provide at least a unique name, 
the HTTP address of the cluster, and the authentication settings if required. The name can be any string of your choice that
helps you to identify the connect cluster. The name has to be unique among the provided set of connect clusters though.
You can view all available configuration options in the [reference config](../../reference/config).

This sample configuration goes into the configuration file's root level. 

```yaml
connect:
  enabled: true
  clusters:
    - name: datawarehouse # Required field, will be used as identifier in the frontend
      url: http://dwh-connect.mycompany.com:8083
      tls:
        enabled: false # Trusted certs are still allowed by default
      username: admin
      # password: # Set using flag --connect.clusters.0.password=secret
    - name: analytics # Required field, will be used as identifier in the frontend
      url: http://analytics.mycompany.com:8083
      # No auth configured on that cluster, hence no username/password set
```

## Record Deserialization

When consuming messages, Redpanda Console's message viewer is capable of automatically deserializing messages.
It identifies the correct deserialization type by trying to decode the record's key, value, or header with all
available deserialization methods. The supported deserialization methods are:

- Kafka's internal binary formats (for example the `__consumer_offsets` topic )
- JSON
- JSON Schema with schema registry encoding
- XML
- Avro with schema registry encoding
- Protobuf
- Protobuf with schema registry encoding
- Messagepack (only for topics that are explicitly enabled to test MessagePack)
- UTF-8 / Strings

Decoded messages will be rendered as JSON objects and can also be used as JavaScript object in
[push filters](../programmable-push-filters).
If none of these deserialization attempts appear to be successful, Redpanda Console will render the byte array
in a hex viewer. Encoding formats that are not self-contained requires additional configuration. 

## Schema Registry

To deserialize Kafka records that have been encoded with a schema registry compatible serializer, such as  
`io.confluent.kafka.serializers.KafkaAvroSerializer`, you must have a valid schema registry configuration in Redpanda Console. 

Additionally you can inspect, edit, and delete the registered schemas. 

```yaml
kafka:
  schemaRegistry:
    enabled: true
    urls: ["https://my-schema-registry.com"]
    username: console
    password: redacted # Or set using flags or env variable
  # If you want to enable protobuf support enable it here
  protobuf:
    enabled: true
    schemaRegistry:
      enabled: true
      refreshInterval: 5m
```

Messages that have been serialized using Confluent's KafkaProtobufSerializer can only be deserialized if the schema registry is configured. 
Unlike other providers, the schema registry does not require you to set up mappings that define what topics use which prototypes. Instead, 
this information is inferred from the messages, and the schema registry finds the right prototype for deserialization.

The protobuf deserializer uses the same schema registry client that is configured under `kafka.schemaRegistry`. See
[Schema registry](../schema-registry) for information about how to set up the schema registry in Redpanda Console.
A valid configuration for the Protobuf support with schema registry support looks like this:

```yaml
kafka:
  schemaRegistry:
    enabled: true
    urls: ["https://my-schema-registry.com"]
    username: console
    password: redacted # Or set using flags or env variable
  protobuf:
    enabled: true
    schemaRegistry:
      enabled: true # This tells the proto service to consider the schema registry when deserializing messages
      refreshInterval: 5m # How often the compiled proto schemas in the cache should be updated
```

## Protobuf Deserialization

If you have one or more topics that contain Protobuf serialized messages, you can configure Redpanda Console to deserialize 
the binary content into JSON, which makes the message human-readable. The resulting message can also be used in the 
[programmable push filters](../programmable-push-filters) like a JavaScript object.

Protobuf serialization is commonly used with Kafka clusters in two ways:
- With schema registry (schema meta information gets embedded as part of the record's value)
- To write Protobuf serialized content into Kafka topics without a binary or custom wrapper

This is a technical difference because most Kafka clients that serialize Protobuf messages put the serialized byte array
into a binary wrapper that contains meta information such as the schema ID or the used prototypes. Therefore, the application
that deserializes the Kafka records has to recognize the format. Redpanda Console supports both formats. The deserialization process
requires Redpanda Console to be aware of the used `.proto` files as well as a mapping what prototype should be used for each topic.
This information can either be sourced from the schema registry or by providing additional configuration so that the files
can be pulled from the local filesystem or a GitHub repository.

:::info
To support imports, all prototypes are first registered in a proto registry, so that your imports can be resolved. 
You must also ensure that all imported prototypes are part of the repository.
Standard types (such as Google's timestamp type) are included by default, so you don't need to add them.
:::

### Local filesystem

You can provide all required proto files by mounting them from your filesystem. All files must use the `.proto` file extension. 
In the `config.yaml` file, configure Redpanda Console to search one or more paths for your provided proto files so that it can 
build a registry with all types:

```yaml
kafka:
  protobuf:
    enabled: true
    mappings:
      - topicName: orders
        valueProtoType: fake_model.Order # You can specify the proto type for the record key and/or value (just one will work too)
        keyProtoType: package.Type
    fileSystem:
      enabled: true
      refreshInterval: 5m # 5min is the default refresh interval
      paths:
        - /etc/protos
```

### GitHub repository

To provide the proto files through a GitHub repository, first place the files in a directory. The directory doesn't matter, because 
Redpanda Console searches for all Proto files up to a directory depth of five levels. To
use multiple different import paths, set the `importPaths` property. For example, if your repository includes
third-party Protobuf types, such as Google's types, that are in a different directory to your own types, set the `importPaths` property to the paths of both directories.

Enable `git` in the `config.yaml` file, as shown in the following example.

```yaml
kafka:
  protobuf:
    enabled: true
    mappings: []
      - topicName: xy
        valueProtoType: fake_model.Order # You can specify the proto type for the record key and/or value (just one will work too)
        keyProtoType: package.Type
    # importPaths is a list of paths from which to import Proto files into Redpanda Console.
    # Paths are relative to the root directory.
    # The `git` configuration must be enabled to use this feature.
    importPaths: []
    git:
      enabled: true
      refreshInterval: 5m
      repository:
        url: https://github.com/redpanda-data/owlshop-protos.git
      basicAuth:
        enabled: true
        username: token # API token from basic auth
        password: redacted
```

### Topic mapping configuration

If you don't use the schema registry for Protobuf deserialization, you must provide a mapping configuration so that Redpanda Console is aware of what
Proto types it should use for each Kafka topic.
Assume you have a Kafka topic called `address-v1` and the respective address.proto file in your GitHub repository, which looks like the following:

```proto
syntax = "proto3";
package fake_models;

option go_package = "pkg/protobuf";

message Address {
  int32 version = 1;
  string id = 2;
  message Customer {
    string customer_id = 1;
    string customer_type = 2;
  }
}
```

The required mapping configuration looks like the following:

```yaml
kafka:
  protobuf:
    enabled: true
    mappings:
    - topicName: address-v1
        valueProtoType: fake_model.Address # The full prototype URL is required
        # keyProtoType: The key is a plain string in Kafka, hence we don't have a prototype for the record's key
```

## Topic Documentation

You can embed your topic's documentation into the Redpanda Console user interface by providing access to a GitHub repository that hosts your documentation files in Markdown format. 


### Integrating topic documentation into Redpanda Console

Redpanda Console clones the provided GitHub repository, recursively iterates through all directories in the repository (up to a max depth of 5) and stores all `.md` files it finds in memory.
The "Documentation" tab in the frontend will show the markdown of the file matching the name of the Kafka topic.

| Path/Filename        | Kafka Topic Name | Matches            |
| -------------------- | ---------------- | ------------------ |
| ordersv2.md          | orders-v2        | :x:                |
| Orders-v2.md         | orders-v2        | :x:                |
| orders-v2.md         | orders-v2        | :white_check_mark: |
| /orders/orders-v2.md | orders-v2        | :white_check_mark: |

### Configuration

In addition to the repository URL and branch, you usually need to configure authentication credentials so that you can access private repositories.
Redpanda Console supports SSH as well as basic auth. If neither is specified you could still pull publicly accessible repositories.

Following is the configuration:

```yaml
console:
  topicDocumentation:
    enabled: true
    git:
      enabled: true
      repository:
        url: https://github.com/redpanda-data/topic-docs
        branch: master
      # How often Console shall pull the repository to look for new files.
      # Set to 0 to disable periodic pulls
      refreshInterval: 1m
      # Basic Auth
      # If you want to use GitHub's personal access tokens use `token` as username 
      # and pass the token as password
      basicAuth:
        enabled: true
        username: token
        password: ""
      # SSH Auth
      ssh:
        enabled: false
        username: ""
        privateKey: ""
        privateKeyFilepath: ""
        passphrase: ""
```

## Programmable Push Filters

You can use Redpanda Console's programmable push filters to search for a specific message within a Kafka topic.
Programmable push filters enable you to write a TypeScript/JavaScript function body that **runs in the backend** and is called for 
every individual Kafka record. The code has to return a boolean. If your code returns `true`, the backend sends the record to the frontend. 
Otherwise the record will be skipped and Redpanda Console will continue to consume records until the selected number
of max search results has been reached or "the end" of the topic hit.

Redpanda Console injects the following variables into your function, which you can use in your filter code:

- `partitionId` - the record's partition ID
- `offset` - the record's offset within its' partition
- `key` - the record's key in its decoded form
- `value` - the record's value in its decoded form

:::note
Keys and values are passed into your JavaScript code in their decoded form. That means the
deserialization logic (for example, decode an Avro serialized byte array to a JSON object)is applied first, before injecting it into
the JavaScript function. If your message is presented as a JSON object in the UI, you can also access it
like a JavaScript object in your filter code.
:::

If you have a series of Avro, JSON or Protobuf encoded record values which deserialize to JSON objects like this:

```json
{
    "event_type": "BASKET_ITEM_ADDED",
    "event_id": "777036dd-1bac-499c-993a-8cc86cee3ccc"
    "item": {
        "id": "895e443a-f1b7-4fe5-ad66-b9adfe5420b9",
        "name": "milk"
    }
}
```

```ts
return value.item.id == "895e443a-f1b7-4fe5-ad66-b9adfe5420b9"
```

Redpanda Console allows you to use more than one filter function at the same time. If you start a search while having multiple
filters active, they are combined with a logical OR. Accordingly, as soon as one function returns true, the record will be sent
to the frontend.

### Resource usage and performance

You can use Redpanda Console's filter engine against topics with millions of messages, as the filter code is evaluated in the backend
where more resources are available. However, while the filter engine is fairly efficient it will potentially consume all available CPU
resources and may cause significant network traffic due to the number of consumed Kafka messages.

Usually the performance is constrained by the available CPU resources. Depending on the used JavaScript code and the messages, the expected
performance is around ~15k-20k filtered messages per second for each available core. The request is only processed on a single instance and
cannot be shared across multiple instances.

## HTTP Path Rewrites

To host Redpanda Console under an HTTP path different from the root path (for example `https://my-company.com/redpanda/console`),
then you need to configure this in Redpanda Console. If you host Redpanda Console at a root path (for example under a sub-domain, such as `https://console.redpanda.my-company.com`),
you don't need to configure HTTP path rewrites.

### Configuration

To configure HTTP path rewrites, you must edit the following properties in the console.yaml file:

- `basePath`
- `setBasePathFromXForwardedPrefix`
- `stripPrefix`

As shown in the following code snippet, properties are defined in the server block.

```yaml
server:
  # basePath is the sub-path under which Console will be hosted.
  # If you have a reverse proxy in front of Console, that sets
  # the `X-Forwarded-Prefix` header and the configuration property
  # setBasePathFromXForwardedPrefix is true, you don't need to set
  # this.
  basePath: ""

  # If true, Console will check the `X-Forwarded-Prefix` header
  # on all incoming requests. If the header is present, its value
  # will be used as path prefix.
  setBasePathFromXForwardedPrefix: true

  # Some reverse proxies (like Traefik with its StripPrefix middleware)
  # can remove a prefix from the URL path before forwarding it to
  # downstream services like Console. If a prefix is set, it must be
  # removed at some point before reaching Console's internal routing.
  # We recommend that only one part of the stack removes the
  # prefix. If you are using a reverse proxy that modifies the
  # request path, you should either disable stripPrefix or
  # configure the proxy so it doesn't modify the path of a request.
  stripPrefix: true
```

## Single Sign On

:::info
This feature requires an [Enterprise license](../../../introduction/licenses). To upgrade, contact [Redpanda sales](https://redpanda.com/try-redpanda?section=enterprise-cloud).
:::

### Authentication

Redpanda Console supports authentication via OAuth 2.0 or OIDC for external identity providers, such as:
- [Google](../../single-sign-on/identity-providers/google)
- [GitHub](../../single-sign-on/identity-providers/github)
- [Okta](../../single-sign-on/identity-providers/okta)
- [Generic OIDC](../../single-sign-on/identity-providers/generic-oidc)

You can use one or more login providers at the same time. To enable SSO authentication 
you must create an OAuth application for your organization first. Visit the respective
documentation page for guidance to setup your desired identity provider in Console.
Afterwards you can configure your identity provider in Redpanda Console by providing the
clientId and clientSecret in the configuration block for your provider. The configuration
to add Google login support looks like this:

```yaml
login:
  enabled: true
  # jwtSecret is a secret that is used to sign and encrypt the JSON Web tokens
  # that are used by the backend for session management.
  jwtSecret: abcadsdadasdasdas
  google:
    enabled: true
    clientId: redacted.apps.googleusercontent.com
    clientSecret: redacted # can be set via environment variable
    # The directory config is optional. You have to configure it if you want to use
    # Google groups in your RBAC role bindings.
    # directory:
    #  serviceAccountFilepath: /etc/secrets/google-sa.json
    #  # targetPrincipal is the user that shall be impersonated
    #  # for the Google Admin API calls.
    #  targetPrincipal: admin@mycompany.com
```

By default, users don't have any permissions in Redpanda Console. This also includes permission
to login at all. Thus authentication and authorization must always be used together.
Continue with the authorization configuration by reading the RBAC-based [authorization
concept](../authorization).

### Authorization

Redpanda Console uses role-based access control (RBAC) to restrict system access to authorized users.
All configurations have to be provided via YAML files. Console will load these files at startup.
This page describes the concept, the available roles, and how you can bind roles to your users.

:::note
This page describes RBAC in Redpanda Console and therefore manages access only for 
Console user but not clients that interact via the Kafka API. To restrict Kafka API access, 
you need to use Kafka ACLs.
:::

#### RBAC concepts

You can control access to different resources in Console by binding one of the existing roles (admin, editor, viewer)
to one or more users. Besides binding roles to individual users, you can
also use user groups (for example, Google groups) from your configured
identity providers. Users who have multiple roles assigned will receive the
union of all permissions that have been defined in the bound roles.

#### Roles

Each role has a name, as well as a set of permissions, which define the user permissions when the 
role is bound to a user. Console comes with three primitive roles:

**Role `viewer`**

The viewer role grants you the permissions to view all resources within Console. This includes:
- Viewing all topic aspects (messages, configs, partition, using search filters)
- Viewing all cluster aspects (node configs, acls, service accounts, quotas)
- Viewing all consumer group aspects (consumer groups, group offsets and lags)
- Viewing all schema registry aspects (registered schemas with their contents)
- Viewing all Kafka connect aspects (list configured clusters and their connectors including the status and connector configs)

It does not include permissions to view the list of Console users (admin tab) that are allowed to use Console.

**Role `editor`**

The editor role grants all permissions that come with the `viewer` role and additionally includes:

- Managing all topic aspects (create topic, delete topic, publish and delete topic records, ...)
- Managing all cluster configuration aspects (editing node or cluster configs, ...)
- Managing all consumer group aspects (edit group offsets, delete group offsets)
- Managing all Kafka connect aspects (create/update/delete or start/pause/stop connectors)

It does not include the permission to create/remove ACLs or to create or remove a service account.

**Role `admin`**

The editor role grants all permissions that come with the `editor` role and additionally includes:

- Managing all service account aspects (create/remove service account)
- Manage all ACL aspects (create/remove ACLs)

:::note
You cannot create your own roles with a custom set of permissions.
:::

#### Role bindings

To grant users the permissions defined in a role, you must bind the role to a user or a group.
Each role binding holds a list of subjects (users or groups) and a reference to the role being granted.
Optionally you can add metadata (key-value pairs) which may help you to manage your role bindings. Console shows the metadata
 in the UI, so that it helps you to understand how a specific user got its permissions.

Example `role-bindings.yaml` configuration file:

```yaml
roleBindings:
  - roleName: admin
    metadata:
      # Metadata properties will be shown in the UI. You can omit it if you want to
      name: Developers
      creator: John Doe
    subjects:
      - kind: user
        provider: Google
        name: john.doe@redpanda.com
      - kind: group
        provider: Google
        name: dev-team-console@redpanda.com
```

This role binding binds Google account `john.doe@redpanda.com` as well as all Google accounts which are
a member of Google group `dev-team-console@redpanda.com` to the role with name `admin`. Group
memberships are resolved recursively, so that members from nested groups are also considered.
Users who have multiple roles assigned through role bindings will inherit the union of these roles' permissions.

You can find a [reference config for role bindings](../../reference/role-bindings).

:::caution
To use groups in role bindings you need to configure the [groups sync](#groups-sync) for your respective provider.
:::

#### Subjects

Each subject has three properties that are configurable to bind a role to one or more users.

`kind`: Supported kinds are: `group` and `user`.

`providers`: One of `Google`, `GitHub`, `Okta` and `OIDC`.

`name`: Depending on your `kind` and `provider` the `name` property may refer to different things.
This is an overview to what it refers for each provider:

| Kind    | Provider | Name Reference                                                                                                          |
| ------- | -------- | ----------------------------------------------------------------------------------------------------------------------- |
| `user`  | Google   | Google E-Mail address                                                                                                   |
| `group` | Google   | Google Group Name (which is an E-Mail address)                                                                          |
| `user`  | GitHub   | Login handle / GitHub username                                                                                          |
| `group` | GitHub   | GitHub team name within your GitHub organization                                                                        |
| `user`  | Okta     | Login handle / email                                                                                                    |
| `group` | Okta     | Okta Group ID (not name), for example "00gra1ajmZa1G1ks04x9"                                                            |
| `user`  | OIDC     | Configurable via `login.oidc.userIdentifyingClaimKey` (by default it uses the `sub` claim from the issued access token) |

#### Groups sync

If you want to bind Roles to a set of users (for example GitHub teams or Google Groups) you need to grant
Console additional permissions, so that it can resolve the memberships of these user sets.
You will find more information about the setup in the respective identity provider documentation page.

All group memberships that are used in rolebindings, are resolved at startup. Group memberships
will be cached for 15 minutes. Resolving group memberships proactively is required in order to support
nested groups.


## Identity Providers

:::info
This feature requires an [Enterprise license](../../../introduction/licenses). To upgrade, contact [Redpanda sales](https://redpanda.com/try-redpanda?section=enterprise-cloud).
:::

### Generic OIDC

If you would like to integrate an OpenID Connect (OIDC) compatible identity provider that is not yet natively supported in Console,
you can configure the generic OIDC provider. To do so, you first have to create an OAuth application in your identity provider
and then provide this application's credentials in the configuration:

- **Application type:** Web application
- **Authorized redirect URI:** `https://console.yourcompany.com/login/callbacks/oidc`

```yaml
login:
  enabled: true

  # jwtSecret is a random string of at least 10 characters that must be the same for all Console instances. 
  # This string is used to sign and validate the user session JSON Web Tokens (JWT). 
  # If this string changes, logged-in Console users will be logged out and will have to initiate a 
  # new session by logging in again.
  jwtSecret: ""

  oidc:
    # Whether or not the OIDC provider should be initialized
    enabled: true

    # OAuth application client id
    clientId: ""

    # OAuth application client secret
    clientSecret: ""

    # IssuerUrl is the identity provider's URL; for example, https://accounts.google.com.
    # Console will send a GET request to `${issuerUrl}/.well-known/openid-configuration` 
    # and the `issuer` returned in the response has to match this issuer url.
    issuerUrl: ""

    # IssuerTLS is the TLS configuration used by the HTTP client to send requests
	  # to the IssuerURL. If you don't set any certificate paths, the IssuerTLS defaults to
    # the system cert pool.
    issuerTls:
      caFilepath:
      certFilepath:
      keyFilepath:

    # DisplayName is the name that shall be shown on the login page for this identity provider
    displayName: ""

    # UserIdentifyingClaimKey is a relevant property if you want to use a specific claim key
    # to identify users in the role binding. A claim key is part of the identity provider's
    # issued access token payload.
    # By default, we will use the 'sub' claim key, which usually resolves to the unique ID 
    # within the identity provider. The value of this claim is compared against what you
    # use in the roleBindings for the `name` property.
    userIdentifyingClaimKey: "sub"
```

:::note
The `userIdentifyingClaimKey` can only be used for claims that have a string value. You cannot use it for the `groups` claim in AzureAD, for example, because the claim value is a string array.
:::

#### Define role-bindings

After you set up the OIDC login configuration, you can bind users to roles. Below is a sample
role binding:

```yaml
roleBindings:
  - metadata:
      name: Developers
    subjects:
        # Kind must always be set to `user` for the OIDC provider, as the claims always belong to 
        # an individual user.  This is also true if you match a claim against a group.
      - kind: user
        provider: OIDC
        # Name must match the value of your configured claim key
        name: joe@yourcompany.com
    roleName: editor
```

#### Troubleshooting

#### Used claim key did not exist in user's id token

If the claim key in a role binding does not exist in the ID token, Redpanda Console prints
an error message in the backend to assist you with this. The error message contains the claim key 
that Redpanda Console tried to look up, as well as all existing claim keys for this specific user.

Here is an example error message:

```
{
  "level": "error",
  "msg": "the specified user identifying claim does not exist for the user that has logged in",
  "found_claim_keys": ["oid", "aud", "sub"],
  "used_claim_key": "uid"
}
```

#### Find your claim keys and values

If you are unsure about which claim keys and values that your identity provider attached to your ID token,
you can extract them from the JSON web token that is sent to your browser as a cookie. Because the claim values may be 
sensitive, Redpanda Console never logs them in the backend.

1. Open the Redpanda Console login page. Don't click the OIDC login button yet.

1. Open your browser's developer tools and inspect the network requests.

1. If your browser has the option to preserve logs, enable it.
  Without this option enabled, some browsers such as Google Chrome truncate the network request logs after a redirection.
  
1. Click the OIDC login button and authenticate with your identity provider.

1. Search the network requests in your browser's developer tools for a request that starts with the relative path `/auth/callbacks/oidc?code=`.

1. Copy the value of the `jwt` cookie in the `set-cookie` header. The value of that cookie is an encrypted and compressed JSON web token.

1. Send the JSON web token to Redpanda Console to decode.

  ```bash
  curl -sL -X POST 'https://your-console-url.com/admin/session-token/decode' \
  -H 'Content-Type: application/json' \
  --data-raw '{
      "token": "<your-token>"
  }'
  ```

  The response is a JSON object, which includes your token in the `oAuthToken.access_token` field.

8. Paste your token into [https://jwt.io/](https://jwt.io/), where you can inspect all your decoded claim keys.


### Github

Integrating Redpanda Console with GitHub allows your users to use their GitHub identities to sign-in to Console.
This guide assumes you already have a GitHub account and permissions to create Applications within your organization.

#### Create an OpenID connect application

Follow this [GitHub guide](https://docs.github.com/en/developers/apps/building-oauth-apps/creating-an-oauth-app) to create
an OAuth application at GitHub. You can create the OAuth application either under your personal account or under any
organization you have admin access to. As you follow the guide to create the GitHub OAuth app, use the following inputs
when you are asked for it:

:::note
Below configurations assume that you want to host Redpanda Console so that it would be accessible via
`https://console.yourcompany.com`.
:::

- **Application name:** Any descriptive name for your specific Console deployment (for example Console Analytics Prod)
- **Homepage URL:** `https://console.yourcompany.com`
- **Authorization callback URL:** `https://console.yourcompany.com/login/callbacks/github`
- **Enable device flow:** False / Not selected

```yaml
login:
  enabled: true

  # jwtSecret is a random string of at least 10 characters that must be the same for all Console instances. 
  # This string is used to sign and validate the user session JSON Web Tokens (JWT). 
  # If this string changes, logged-in Console users will be logged out and will have to initiate a 
  # new session by logging in again.
  jwtSecret: ""

  github:
    enabled: true
    clientId: ""
    # ClientSecret is sensitive. You can provide this config also via the
    # the environment variable LOGIN_GITHUB_CLIENTSECRET
    clientSecret: ""
    # The directory config is only required if you want to use GitHub
    # teams in your role bindings. Described further in the next section.
    # directory:
    #   personalAccessToken: ""
```

#### RBAC GitHub teams sync

If you want to bind roles to GitHub teams from an organization you have to setup a personal access token in GitHub, so that Redpanda console can retrieve groups
and their memberships using the GitHub API. The personal access token has to be created on an account that has permissions to view groups in your desired
GitHub organization. Follow [this guide](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token) 
to create the personal access token. When you select the scopes and permissions make sure to include `read:org` and `user:email`.

```yaml
login:
  github:
    # The directory config is only required if you want to use GitHub
    # teams in your role bindings.
    directory:
      personalAccessToken: ""
```

#### Define role-bindings

When you set up the GitHub login configuration, you can bind GitHub users or groups to roles. Following is a sample
role binding:

```yaml
roleBindings:
  - metadata:
      name: Developers
    subjects:
      - kind: group
        provider: GitHub
        name: console-developers # GitHub team name
        organization: redpanda-data # GitHub organization name
      - kind: user
        provider: GitHub
        name: weeco # GitHub handle
    roleName: editor
```

### Google

Integrating Redpanda Console with Google allows your users to use their Google identities to sign in to Console.
This guide assumes you already have a Google account to setup the OAuth application.

### Create an OpenID connect application

Follow this [Google guide](https://developers.google.com/identity/protocols/oauth2/openid-connect#appsetup) to create
an OAuth application at Google. As you follow the guide to create the OAuth app, use the following inputs
when you are asked for it:

:::note
The following configurations are based on the assumption that you want to host Redpanda Console so that it would be accessible using
`https://console.yourcompany.com`.
:::

- **Application name:** Any descriptive name for your specific Console deployment (for example Console Analytics Prod)
- **Application type:** Web application
- **Authorized redirect URI:** `https://console.yourcompany.com/login/callbacks/google`

```yaml
login:
  enabled: true

  # jwtSecret is a random string of at least 10 characters that must be the same for all Console instances. 
  # This string is used to sign and validate the user session JSON Web Tokens (JWT). 
  # If this string changes, logged-in Console users will be logged out and will have to initiate a 
  # new session by logging in again.
  jwtSecret: ""

  google:
    enabled: true
    clientId: ""
    # ClientSecret is sensitive. You can provide this config also via the
    # the environment variable LOGIN_GOOGLE_CLIENTSECRET
    clientSecret: ""
    # The directory config is only required if you want to use Google
    # groups in your role bindings. Described further in the next section.
    # directory:
    #   serviceAccountFilepath: ""
    #   targetPrincipal: ""
```

#### RBAC Google groups sync

If you want to bind roles to Google groups from a workspace organization you have to set up a service account, so that Redpanda Console can retrieve groups
and their memberships using the Google Workspace API. Follow this [guide](https://developers.google.com/admin-sdk/directory/v1/guides/delegation) 
to create the required service account and to delegate domain-wide authority to it. Make sure to create and download the service account key in JSON
format.

You need to make the service account key (a JSON file) available to Console by mounting the file. The Console configuration expects you to specify
the filepath to the JSON file so that it can be loaded at startup. Because only Google users with access to the Admin APIs have access to Google's
Admin SDK Directory API, it is required that the service account impersonates such a user. Specify which user the service account shall impersonate
by setting the `targetPrincipal` to this user's email address.

```yaml
login:
  google:
    # The directory config is only required if you want to use Google
    # groups in your role bindings.
    directory:
      # Path to service account key in JSON format
      # For example: "/etc/mounts/google-sa.json"
      serviceAccountFilepath: ""
      # TargetPrincipal is the user that shall be impersonated by the
      # service account. For example: "admin@yourcompany.com".
      targetPrincipal: ""
```

#### Define role-bindings

When you set up the Google login configuration, you can bind Google users or groups to roles. Following is a sample
role binding:

```yaml
roleBindings:
  - metadata:
      name: Developers
    subjects:
      - kind: group
        provider: Google
        name: engineering@yourcompany.com
      - kind: user
        provider: Google
        name: john.doe@yourcompany.com
    roleName: editor
```

:::note
Group memberships will be resolved proactively in order to support nested groups. If the service account doesn't have permissions
to resolve a certain group memberships, it will be printed in the logs. Group memberships will be cached for 15 minutes before
they will be refreshed.
:::


### Okta

Integrating Redpanda Console with Okta allows your users to use their Okta identities to sign in to Redpanda Console.
This guide is based on the assumption that you already have an Okta account and permissions to create applications within your organization.

#### Create an OpenID connect application

Refer to the [Okta guide](https://developer.okta.com/docs/guides/sign-into-web-app-redirect/-/main/) to create
an application integration for Redpanda Console. As you follow the guide to create the Okta integration, use the following inputs
when prompted:

:::note
The following configurations are based on the assumption that you want to host Redpanda Console so that it is accessible using
`https://console.yourcompany.com`.
:::

- **Redirect URI:** `https://console.yourcompany.com/login/callbacks/okta`
- **Logout Redirect URI:** `https://console.yourcompany.com`
- **Sign-in method:** OIDC - Open ID Connect / Application type: Web Application
- **Assignments:** Select groups that shall be able to use Redpanda Console (authorization can be made more granular using Redpanda Console's RBAC system)

When you create the Okta application you should be able to access the application's client credentials (client ID and client secret).
Put the following credentials into your Redpanda Console configuration:

```yaml
login:
  enabled: true

  # jwtSecret is a random string of at least 10 characters that must be the same for all Console instances. 
  # This string is used to sign and validate the user session JSON Web Tokens (JWT). 
  # If this string changes, logged-in Console users will be logged out and will have to initiate a 
  # new session by logging in again.
  jwtSecret: ""

  okta:
    enabled: true
    # URL to the OIDC endpoint, e.g. "https://yourcompany.com.okta.com"
    url: ""
    clientId: ""
    # ClientSecret is sensitive. You can provide this config also via the
    # the environment variable LOGIN_OKTA_CLIENTSECRET
    clientSecret: ""
    # The directory config is only required if you want to use Okta
    # groups in your role bindings. Described further in the next section.
    # directory:
    #   apiToken: ""
```

#### RBAC Okta groups sync

If you want to bind roles to Okta groups, you must set up an API token in Okta so that Redpanda Console can retrieve groups
and their memberships using the Okta API. To create an API token, refer to the [Okta guide](https://developer.okta.com/docs/guides/create-an-api-token/main/).
After completing the steps in the guide, insert the created API token into the configuration:

```yaml
login:
  okta:
    # The directory config is only required if you want to use Okta
    # groups in your role bindings.
    directory:
      apiToken: ""
```

#### Define role bindings

After setting up the Okta login configuration, you can bind Okta users or groups to roles. Following is a sample
role binding:

```yaml
roleBindings:
  - metadata:
      name: Developers
    subjects:
      - kind: group
        provider: Okta
        name: 00qri1afoAa12G9js04x6 # Okta group id
      - kind: user
        provider: Okta
        name: joe@yourcompany.com # Okta user login
    roleName: editor
```
